{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOP 30K\n",
    "\n",
    "Esta tarea se tiene que ejecutar los martes por la mañana, previo checkeo que los datos están subidos a https://www.ritmogestion.es/listas . Si no están subidos la función dará error. El usuario para entrar en la web es *nmarin* y la contraseña *3-5B0G4W1qWfI6b6*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerias que se van a usar.\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from sys import argv\n",
    "import shutil\n",
    "from utils import get_dates_from_week\n",
    "from utils import get_main_artist\n",
    "from utils import get_info_from_track_and_artist\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import write_to_reporting_db as db\n",
    "import subprocess\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carpeta es: c:\\Users\\nuria01\\Sony Music Entertainment\\ESP Business Intelligence - General\\1_DATA ANALYTICS\\1_BBDD\\6_0_TOP_30K\\Back_up_semanas \n",
      " Mientras que la carpeta para el no back_up es: c:\\Users\\nuria01\\Sony Music Entertainment\\ESP Business Intelligence - General\\1_DATA ANALYTICS\\1_BBDD\\6_0_TOP_30K\n",
      "El trimestre al que pertenece la semana 34 es el 3.\n",
      "El número de semana está comprendido entre los valores adecuados.\n",
      "El usuario: NURIA01 es válido.\n",
      "Vas a ejecutar la semana 34, del año 2024, y el trimestre 3\n",
      "La fecha de inicio es: 2024-08-16\n",
      "La fecha de fin es: 2024-08-22\n"
     ]
    }
   ],
   "source": [
    "# Variables y rutas de las carpetas que vamos a usar durante el codigo\n",
    "usuario = os.getlogin()\n",
    "ruta_script = os.getcwd()\n",
    "carpeta = os.path.join(os.path.dirname(ruta_script),'1_BBDD','6_0_TOP_30K' ,'Back_up_semanas')\n",
    "carpeta_no_backup = os.path.join(os.path.dirname(ruta_script),'1_BBDD','6_0_TOP_30K')\n",
    "print(f'La carpeta es: {carpeta} \\n Mientras que la carpeta para el no back_up es: {carpeta_no_backup}')\n",
    "\n",
    "# Metemos el año y la semana que vamos a ejecutar\n",
    "year = int(input(\"Por favor, ingrese un número de AÑO que vamos a añadir: \"))\n",
    "week = int(input(\"Por favor, ingrese un número de SEMANA que vamos a añadir: \"))\n",
    "# Generamos la variable del trimestre\n",
    "if week < 14:\n",
    "    quarter = 1\n",
    "elif week < 27:\n",
    "    quarter = 2\n",
    "elif week < 40: \n",
    "    quarter = 3\n",
    "elif week < 53: \n",
    "    quarter = 4\n",
    "else: print('Semana fuera de rango')\n",
    "print(f'El trimestre al que pertenece la semana {week} es el {quarter}.')   \n",
    "\n",
    "# Verificar si el número ingresado coincide con el número de filas del DataFrame\n",
    "if week > 53 or week < 1:\n",
    "    print(f\"El número ingresado para la semana está mal, tiene que ser un número entre 1 y 52.\")\n",
    "    sys.exit()\n",
    "print('El número de semana está comprendido entre los valores adecuados.')\n",
    "\n",
    "if usuario.lower() not in ['alco003', 'nuria01']:\n",
    "    sys.exit('Error: el valor de la variable usuario: no es válido')\n",
    "print(f'El usuario: {usuario} es válido.')\n",
    "\n",
    "print(f'Vas a ejecutar la semana {week}, del año {year}, y el trimestre {quarter}')\n",
    "\n",
    "# Generamos las fechas que vamos a necesitar\n",
    "fecha_inicio = get_dates_from_week(week,year)['inicio']\n",
    "fecha_fin = get_dates_from_week(week,year)['fin']\n",
    "year_inicio = fecha_inicio[:4] \n",
    "mes_inicio = fecha_inicio[5:7]\n",
    "dia_inicio = fecha_inicio[8:]\n",
    "year_fin = fecha_fin[:4] \n",
    "mes_fin = fecha_fin[5:7]\n",
    "dia_fin = fecha_fin[8:]\n",
    "fecha = get_dates_from_week(week,year)['inicio']\n",
    "print(f'La fecha de inicio es: {fecha_inicio}')\n",
    "print(f'La fecha de fin es: {fecha_fin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya tenemos el dataframe creado\n",
      "paso 1\n",
      "año\n",
      "semana\n",
      "semana_actual\n",
      "posicion_maxima\n",
      "streams_semana_actual\n",
      "streams_semana_anterior\n",
      "streams_acumulados\n",
      "unidades_semana_actual\n",
      "unidades_acumuladas_adsupported\n",
      "unidades_acumuladas_premium\n",
      "unidades_acumuladas\n",
      "paso 2\n",
      "(30000, 23)\n"
     ]
    }
   ],
   "source": [
    "def obtener_top30k_ritmogestion(year, week):\n",
    "    username = 'nmarin'\n",
    "    password = '3-5B0G4W1qWfI6b6'\n",
    "    nombre_lista = 'Top 30.000 Streaming' \n",
    "    base_url = \"https://ritmogestion.es\"\n",
    "    auth_endpoint = \"/listas/ws/login\"\n",
    "    auth_url = base_url + auth_endpoint\n",
    "    \n",
    "    auth_data = {\n",
    "        \"username\": username,\n",
    "        \"password\": password\n",
    "    }\n",
    "    \n",
    "    auth_headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(auth_url, json=auth_data, headers=auth_headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token = response.json().get(\"data\", {}).get(\"token\")\n",
    "        if not token:\n",
    "            raise Exception(\"Autenticación exitosa, pero no se encontró ningún token en la respuesta.\")\n",
    "    else:\n",
    "        raise Exception(f\"Error en la autenticación: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    lista_dict = {\n",
    "        \"Top 100 Full track\": \"D0\",\n",
    "        \"Top 100 Canciones\": \"D3\",\n",
    "        \"Top Radio\": \"D4\",\n",
    "        \"Top Radio Musical\": \"D5\",\n",
    "        \"Top 100 Álbumes Ventas\": \"V0\",\n",
    "        \"Top 20 Recopilaciones\": \"V1\",\n",
    "        \"Top 1.000 Álbumes\": \"V10\",\n",
    "        \"Top 100 Vinilos\": \"V11\",\n",
    "        \"Top DVD Musical\": \"V2\",\n",
    "        \"Top 200 Streaming\": \"V3\",\n",
    "        \"Top Singles\": \"V4\",\n",
    "        \"Top 200 Artistas y Recopilaciones\": \"V5\",\n",
    "        \"Top 100 Streaming Álbumes\": \"V6\",\n",
    "        \"Top 30.000 Streaming\": \"V7\",\n",
    "        \"Top 100 Álbumes\": \"V8\"\n",
    "    }\n",
    "    \n",
    "    list_type = lista_dict.get(nombre_lista)\n",
    "    if not list_type:\n",
    "        raise ValueError(f\"Error: No se encontró el tipo de lista para {nombre_lista}\")\n",
    "    \n",
    "    list_endpoint = \"/listas/ws/getChart\"\n",
    "    list_url = base_url + list_endpoint\n",
    "    \n",
    "    list_headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    list_params = {\n",
    "        \"year\": year,\n",
    "        \"week\": week,\n",
    "        \"type\": list_type,\n",
    "        \"lang\": \"es\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(list_url, headers=list_headers, params=list_params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        chart_data = data.get(\"data\", {}).get(\"chart\", [])\n",
    "        df = pd.DataFrame(chart_data)\n",
    "        print('Ya tenemos el dataframe creado')\n",
    "    else:\n",
    "        raise Exception(f\"Error al obtener los datos de la lista: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    dtypes_completo = {\n",
    "        '%_dif': str,\n",
    "        'ad_supported': str,\n",
    "        'año': int,\n",
    "        'artista': str,\n",
    "        'audiencia': int,\n",
    "        'audiencia_total': int,\n",
    "        'certificados': str,\n",
    "        'code': str,\n",
    "        'comprobar_posible_certificado': str,\n",
    "        'distribuidor_int': str,\n",
    "        'fecha_lanzamiento': str,\n",
    "        'label': str,\n",
    "        'Lista': str,\n",
    "        'posicion_maxima': int,\n",
    "        'premium': str,\n",
    "        'SEA_acumuladas': int,\n",
    "        'SEA_semana_actual': int,\n",
    "        'sello': str,\n",
    "        'semana': int,\n",
    "        'semana_actual': int,\n",
    "        'semana_anterior': str,\n",
    "        'semanas_lista': int,\n",
    "        'streams_acumulados': int,\n",
    "        'streams_semana_actual': int,\n",
    "        'streams_semana_anterior': int,\n",
    "        'titulo': str,\n",
    "        'tocadas': int,\n",
    "        'total_acumuladas': int,\n",
    "        'total_semana_actual': int,\n",
    "        'unidades_acumuladas': int,\n",
    "        'unidades_acumuladas_adsupported': int,\n",
    "        'unidades_acumuladas_premium': int,\n",
    "        'unidades_semana_actual': int,\n",
    "        'ventas_acumuladas': int,\n",
    "        'ventas_semana_actual': int,\n",
    "        'ventas_semana_anterior': int\n",
    "    }\n",
    "\n",
    "    print('paso 1')\n",
    "    \n",
    "    dtypes_df = {col: dtypes_completo[col] for col in df.columns if col in dtypes_completo}\n",
    "    \n",
    "    for col, dtype in dtypes_df.items():\n",
    "        if dtype in [int, float]:\n",
    "            print(col)\n",
    "            df[col] = df[col].fillna(0).astype(dtype)\n",
    "        else:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "    \n",
    "    print('paso 2')\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = obtener_top30k_ritmogestion(year = year, week = week)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL ARCHIVO SE ENCUENTRA EN c:\\Users\\nuria01\\Sony Music Entertainment\\ESP Business Intelligence - General\\1_DATA ANALYTICS\\1_BBDD\\6_0_TOP_30K\\Back_up_semanas\\W34\\top10000_streaming_w_34_2024.csv\n",
      "Creamos columna \"Artista principal\" que nos permitirá trabajar con las categorizaciones.\n",
      "Aplicamos la guncion de utils get_main_artist.\n",
      "Estos son los artistas que están mal: \n",
      "Incluimos - en las columnas de sello, label y distribuidor vacías para eliminar Nan, que daba error.\n",
      "Modificación \"manual\" de los nombres de distribuidores para que sean siempre iguales.\n",
      "Rellenar ISRC cada semana\n",
      "Ecncapsulado en una función para evitar ejecutarlo, obitene el isrc via Spotify de las canciones que no lo tienen tras buscarlo en track_db\n",
      "Guardamos el top 10000 de la semana c:\\Users\\nuria01\\Sony Music Entertainment\\ESP Business Intelligence - General\\1_DATA ANALYTICS\\1_BBDD\\6_0_TOP_30K\\Back_up_semanas\\W34\\top10000_streaming_w_34_2024_corregido.csv\n",
      "Hacemos backup del acumulado de la semana anterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nuria01\\\\Sony Music Entertainment\\\\ESP Business Intelligence - General\\\\1_DATA ANALYTICS\\\\1_BBDD\\\\6_0_TOP_30K\\\\Back_up_semanas\\\\W34\\\\top_10000_streaming_2021_backup_33.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10000_folder = carpeta\n",
    "week_path = os.path.join(top_10000_folder, f'W{week:02}')\n",
    "#Crear carpeta para la semana\n",
    "if not os.path.isdir(week_path):\n",
    "    os.mkdir(week_path)\n",
    "\n",
    "input_filename = os.path.join(week_path, f'top10000_streaming_w_{week:02}_{year}.csv')\n",
    "df.to_csv(input_filename, encoding='latin-1', errors='ignore')\n",
    "print(f'EL ARCHIVO SE ENCUENTRA EN {input_filename}')\n",
    "output_filename = f'{os.path.splitext(input_filename)[0]}_corregido.csv'\n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "df_output[\"Año\"] = df[\"año\"].apply(int)\n",
    "df_output['Quarter'] = quarter\n",
    "df_output[\"Semana\"] = df[\"semana\"].apply(int)\n",
    "list_date = datetime.strptime(fecha, '%Y-%m-%d')\n",
    "df_output['Fecha'] = pd.to_datetime(list_date, format=\"%Y-%m-%d\")\n",
    "df_output[\"Posición\"] = df[\"semana_actual\"].apply(int)\n",
    "df_output[\"Pos. Anterior\"] = df[\"semana_anterior\"].fillna(0).apply(lambda x: int(x) if x != 'None' else 0)\n",
    "df_output[\"Pos. Máxima\"] = df[\"posicion_maxima\"].apply(int)\n",
    "df_output[\"Main Artist\"] = '-'\n",
    "df_output[\"Artista\"] = df[\"artista\"]\n",
    "df_output[\"Título\"] = df[\"titulo\"]\n",
    "df_output[\"Sello\"] = df[\"sello\"]\n",
    "df_output['Label'] = df['label']\n",
    "df_output['Distribuidor'] = df['distribuidor_int']\n",
    "df_output[\"Streams\"] = df[\"streams_semana_actual\"]\n",
    "df_output[\"Streams Anterior\"] = df[\"streams_semana_anterior\"]\n",
    "df_output[\"Streams Acum.\"] = df[\"streams_acumulados\"]\n",
    "df_output['AdSupported'] = df['ad_supported']\n",
    "df_output[\"Premium\"] = df[\"premium\"]\n",
    "df_output['% Dif.'] = df['%_dif']\n",
    "df_output[\"Code\"] = df[\"code\"]\n",
    "df['fecha_lanzamiento'] = df['fecha_lanzamiento'].replace('None', pd.NaT)\n",
    "df_output[\"Release date\"] = pd.to_datetime(df['fecha_lanzamiento'], format=\"%d-%m-%Y\", errors='coerce')\n",
    "\n",
    "print('Creamos columna \"Artista principal\" que nos permitirá trabajar con las categorizaciones.') \n",
    "\n",
    "# Incluimos '-' en las filas de 'Artista' vacías para eliminar 'Nan' que daba error. \n",
    "df_output.loc[df['artista'].isnull(), 'Main Artist'] = '-'\n",
    "df_output.loc[df_output['Artista'].isna()==True, 'Artista'] = '-'\n",
    "# df_output['Artista'] = df_output['Artista'].fillna('-')\n",
    "print('Aplicamos la funcion de utils get_main_artist.')\n",
    "df_output['Main Artist'] = df_output['Artista'].apply(get_main_artist)\n",
    "df_output['Main Artist'] = df_output['Main Artist'].apply(get_main_artist)\n",
    "\n",
    "# NUEVO: HACER ESTO EN LUGAR DE LA REGEX\n",
    "# quitar las comillas de la columna Main Artist\n",
    "df_output['Main Artist'] = df_output['Main Artist'].str.replace('\"', '')\n",
    "print('Estos son los artistas que están mal: ')\n",
    "for idx in df_output.index:\n",
    "    item = df_output.loc[idx, 'Main Artist']\n",
    "    if ';' in item:\n",
    "        # print(item)\n",
    "        df_output.loc[idx, 'Main Artist'] = item.split(';')[0]\n",
    "# suponiendo que tu DataFrame se llama pd_30k\n",
    "df_output['Artista'] = df_output['Artista'].str.replace('\"', '')\n",
    "df_output['Artista'] = df_output['Artista'].str.replace('; ', ' / ')\n",
    "df_output['Artista'] = df_output['Artista'].str.replace(' ;', ' / ')\n",
    "df_output['Artista'] = df_output['Artista'].str.replace(';', ' / ')\n",
    "\n",
    "print('Incluimos - en las columnas de sello, label y distribuidor vacías para eliminar Nan, que daba error.') \n",
    "df_output.loc[df_output['Sello'].isnull(), 'Sello'] = '-'\n",
    "df_output.loc[df_output['Label'].isnull(), 'Label'] = '-'\n",
    "df_output.loc[df_output['Distribuidor'].isnull(), 'Distribuidor'] = '-'\n",
    "df_output.loc[df_output['Distribuidor']== 'None', 'Distribuidor'] = '-'\n",
    "\n",
    "# Creamos lista de 'labels' y 'sellos' con los nombres de distribuidor que están en esas\n",
    "#  columnas, para facilitar las modificaciones. \n",
    "labels = ['ALTAFONTE', 'DISTRO_KID', 'INTERACTIVE', 'DITTO MUSIC', 'LA CUPULA MUSIC', \n",
    "        'INGROOV', 'SYMPHONIC', 'THE ORCHARD', 'MERLIN', 'ONERPM', 'LA_CUPULA_MUSIC',\n",
    "        'LA CÚPULA', 'TUNECORE', 'CDBABY', 'ROUTENOTE', 'DITTO_MUSIC', 'CD BABY', \n",
    "        'APARATAJE MUSIC GROUP']\n",
    "sellos = ['EMPIRE']\n",
    "\n",
    "# Bucle para incluir el nombre del distribuidor, cuando está contenido en 'Label'. \n",
    "for label in labels:\n",
    "    df_output.loc[df_output['Label'].str.contains(label), 'Distribuidor'] = label\n",
    "\n",
    "# Bucle para incluir el nombre del distribuidor, cuando está contenido en 'Sello'. \n",
    "for sello in sellos:\n",
    "    df_output.loc[df_output['Sello'].str.contains(sello), 'Distribuidor'] = sello\n",
    "\n",
    "print('Modificación \"manual\" de los nombres de distribuidores para que sean siempre iguales.')  \n",
    "df_output.loc[df_output['Distribuidor'] == 'DISTRO_KID', 'Distribuidor'] = 'DISTRO KID'\n",
    "df_output.loc[df_output['Distribuidor'] == 'DISTROKID', 'Distribuidor'] = 'DISTRO KID'\n",
    "df_output.loc[df_output['Distribuidor'] == 'DITTO_MUSIC', 'Distribuidor'] = 'DITTO MUSIC'\n",
    "df_output.loc[df_output['Distribuidor'] == 'INGROOV', 'Distribuidor'] = 'INGROOVES'\n",
    "df_output.loc[df_output['Distribuidor'] == 'LA_CUPULA_MUSIC', 'Distribuidor'] = 'LA CUPULA MUSIC'\n",
    "df_output.loc[df_output['Distribuidor'] == 'LA CÚPULA', 'Distribuidor'] = 'LA CUPULA MUSIC'\n",
    "\n",
    "df_output['SPNL'] = ''\n",
    "\n",
    "# Modificacmos manualmente aquellas filas que tengan que ser 'Frontline'\n",
    "frontline_date = list_date - timedelta(weeks = 52 * 1.5)\n",
    "old_frontline_date = list_date - timedelta(weeks = 52 * 3.5)\n",
    "type(frontline_date)\n",
    "\n",
    "# Creamos nueva columna: 'SPNL' y la llenamos con el valor ''\n",
    "df_output['SPNL'] = ''\n",
    "df_output.loc[df_output['Release date'] < old_frontline_date , 'SPNL'] = 'Catálogo'\n",
    "df_output.loc[df_output['Release date'] >= frontline_date, 'SPNL'] = 'Frontline'\n",
    "df_output.loc[(df_output['Release date'] >= old_frontline_date) & (df_output['Release date'] < frontline_date), 'SPNL'] = 'Old frontline'\n",
    "\n",
    "# Asumimos que las canciones que no tienen Release Date son muy antiguas (por inspección) y asignamos catálogo. \n",
    "df_output.loc[df_output['Release date'].isnull(), 'SPNL'] = 'Catálogo'\n",
    "\n",
    "# Creamos nueva columna: 'Novedad' con los posibles valores 'Entrada', 'Novedad' o vacía. \n",
    "df_output['Novedad'] = '-'\n",
    "df_output.loc[df_output['Pos. Anterior'] == 0, 'Novedad'] = 'Entrada'\n",
    "\n",
    "new_date = list_date - timedelta(days=6)\n",
    "df_output.loc[(df_output['Pos. Anterior'] == 0) & (df_output['Release date'] >= new_date), 'Novedad'] = 'Novedad'\n",
    "\n",
    "print('Rellenar ISRC cada semana')\n",
    "\n",
    "# Cuando la columna CODE empiece por letra, asignaremos a ISRC el mismo valor que el de\n",
    "#  la columna CODE. \n",
    "df_output['ISRC'] = df_output.loc[df_output['Code'].str.contains(r'^[A-Za-z]'), 'Code']\n",
    "df_output.loc[~df_output['Code'].str.contains(r'^[A-Za-z]'), 'ISRC'] = '-'\n",
    "\n",
    "# Cuando la columna CODE empiece por número, tenemos que buscar el valor para ISRC. \n",
    "# Primero buscaremos en Track_DB y si no lo encontramos, buscaremos en Spotify. \n",
    "df_track_db = pd.read_excel(os.path.join(os.path.dirname(ruta_script),'1_BBDD','6_0_TOP_30K','track_db.xlsx'))\n",
    "\n",
    "df_output['key'] = df_output['Título']+ '_________'+df_output['Main Artist']\n",
    "df_track_db['key'] = df_track_db['Titulo']+ '_________'+df_track_db['Main Artist']\n",
    "\n",
    "tracks_without_isrc = df_output.loc[~df_output['Code'].str.contains(r'^[A-Za-z]')]\n",
    "\n",
    "for key in tracks_without_isrc['key']:\n",
    "    isrc = df_track_db.loc[df_track_db['key'] == key, 'Spotify ISRC']\n",
    "    if len(isrc) > 0:\n",
    "        df_output.loc[df_output['key'] == key, 'ISRC'] = list(isrc)[0]\n",
    "\n",
    "print('Ecncapsulado en una función para evitar ejecutarlo, obitene el isrc via Spotify de las canciones que no lo tienen tras buscarlo en track_db')\n",
    "def get_info_from_spotify(df_output):\n",
    "    tracks_without_isrc = df_output.loc[df_output['ISRC'] == '-']\n",
    "    tracks = tracks_without_isrc['Título']\n",
    "    artists = tracks_without_isrc['Main Artist']\n",
    "    info = [get_info_from_track_and_artist(track, artist)[0] for track, artist in zip(tracks, artists) ]\n",
    "    df_info = pd.DataFrame(info, columns=['name','release_date','id','isrc','artists'])\n",
    "\n",
    "fecha_buena = []\n",
    "for i in range(len(df_output.Fecha)):\n",
    "    fecha_buena.append(get_dates_from_week(int(df_output['Semana'][i]), int(df_output['Año'][i]), format='%d/%m/%Y')['inicio'])\n",
    "df_output['Fecha'] = fecha_buena\n",
    "\n",
    "print(f'Guardamos el top 10000 de la semana {output_filename}') \n",
    "df_output.to_csv(output_filename, sep=\";\", index=False, encoding='latin-1', errors='ignore')\n",
    "\n",
    "top_10000_folder_no_backup = carpeta_no_backup\n",
    "\n",
    "acumulado_filename = os.path.join(top_10000_folder_no_backup, 'top_10000_streaming_2021.csv')\n",
    "acumulado_backup_filename = os.path.join(top_10000_folder,f'W{week:02}', f'top_10000_streaming_2021_backup_{week-1:02}.csv')\n",
    "\n",
    "print('Hacemos backup del acumulado de la semana anterior')\n",
    "shutil.copy2(acumulado_filename, acumulado_backup_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria01\\AppData\\Local\\Temp\\2/ipykernel_29648/737899958.py:2: DtypeWarning: Columns (14,15,16,17,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29999    18/12/2021\n",
      "Name: Release date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Actualizamos el acumulado con la semana actual añadiendolo al final\n",
    "df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1')\n",
    "df_output['Release date'] = pd.to_datetime(df_output['Release date'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "print(df_output['Release date'].tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semana\n",
       "1     30000\n",
       "2     30000\n",
       "3     30000\n",
       "4     30000\n",
       "5     30000\n",
       "6     30000\n",
       "7     30000\n",
       "8     30000\n",
       "9     30000\n",
       "10    30000\n",
       "11    30000\n",
       "12    30000\n",
       "13    30000\n",
       "14    30000\n",
       "15    30000\n",
       "16    30000\n",
       "17    30000\n",
       "18    30000\n",
       "19    30000\n",
       "20    30000\n",
       "21    30000\n",
       "22    30000\n",
       "23    30000\n",
       "24    30000\n",
       "25    30000\n",
       "26    30000\n",
       "27    30000\n",
       "28    30000\n",
       "29    30000\n",
       "30    30000\n",
       "31    30000\n",
       "32    30000\n",
       "33    30000\n",
       "Name: Año, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acum[df_acum.Año == 2024]['Año'].groupby(df_acum.Semana).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto C\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos a mano un tema de anuel aa que es TO y aparece como empire\n",
    "condicion = (df_output['Main Artist'] == 'ANUEL AA') & (df_output['Título'] == 'MEJOR QUE YO')\n",
    "condicion_chencho = (df_output['Main Artist'] == 'CHENCHO CORLEONE')\n",
    "condicion_fuerza_regida = (df_output ['Main Artist'] == 'FUERZA REGIDA')\n",
    "condicion_seya = (df_output['Main Artist'] == 'GIMS') & (df_output['Título'] == 'SEYA')\n",
    "condicion_babymonster = (df_output['Main Artist'] == 'BABYMONSTER') & (df_output['Título'] == 'FOREVER')\n",
    "condicion_ozuna = (df_output['Main Artist'] == 'OZUNA') & (df_output['Título'] == 'RAZONES')\n",
    "\n",
    "# Actualiza los valores de la columna \"distribuidor\"\n",
    "df_output.loc[condicion, 'Distribuidor'] = 'THE ORCHARD'\n",
    "df_output.loc[condicion_chencho, 'Distribuidor'] = 'THE ORCHARD'\n",
    "df_output.loc[condicion_fuerza_regida, 'Distribuidor'] = 'THE ORCHARD'\n",
    "df_output.loc[condicion_seya, 'Distribuidor'] = 'BELIEVE DIGITAL'\n",
    "df_output.loc[df_output['Artista'] == 'BLESSD & MALUMA', 'Distribuidor'] = 'ADA'\n",
    "df_output.loc[condicion_babymonster, 'Distribuidor'] = 'OTROS'\n",
    "df_output.loc[condicion_ozuna, 'Distribuidor'] = 'THE ORCHARD'\n",
    "\n",
    "# Lista de títulos de canciones que hay que cambiar\n",
    "titulos = [\"THESE WALLS\", \"END OF AN ERA\", \"FALLING FOREVER\", \"WHATCHA DOING\", \"FRENCH EXIT\", \"HAPPY FOR YOU\", \"ANYTHING FOR LOVE\"]\n",
    "df_output.loc[(df_output['Main Artist'] == 'DUA LIPA') & (df_output['Título'].isin(titulos)), 'Distribuidor'] = 'WARNER MUSIC'\n",
    "print('Punto C')\n",
    "\n",
    "df_output.to_csv(acumulado_filename, sep=\";\", index=False, encoding='latin-1',errors='ignore', mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semana\n",
       "34    30000\n",
       "Name: Año, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output[df_output.Año == 2024]['Año'].groupby(df_output.Semana).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 30000\n",
      "\n",
      " Chunk: 1 of 3\n",
      "Successfully wrote into DB\n",
      "Closed connection to reporting-db.smeanalyticsapps.com\n",
      "\n",
      " Chunk: 2 of 3\n",
      "Successfully wrote into DB\n",
      "Closed connection to reporting-db.smeanalyticsapps.com\n",
      "\n",
      " Chunk: 3 of 3\n",
      "Successfully wrote into DB\n",
      "Closed connection to reporting-db.smeanalyticsapps.com\n",
      "¡¡¡¡PROCESO TERMINADO CON EXITO!!!!\n"
     ]
    }
   ],
   "source": [
    "df_tabla_repDB = pd.read_csv(output_filename, sep=\";\", encoding='latin-1')\n",
    "table_repDB='sandbox.nmarin_top10k_spain'\n",
    "user_repDB='nmarin'\n",
    "password_repDB='9oGiKRWDkPhF'\n",
    "\n",
    "db.write_results_into_db_chunked(df_tabla_repDB,table_repDB,user_repDB,password_repDB,chunk=10000)\n",
    "\n",
    "print('¡¡¡¡PROCESO TERMINADO CON EXITO!!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria01\\AppData\\Local\\Temp\\2/ipykernel_29648/2249689679.py:9: DtypeWarning: Columns (14,15,16,17,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1', dtype=dtypes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ruta_script = os.getcwd()\n",
    "ruta_top30K = os.path.join(os.path.dirname(ruta_script),'1_BBDD','6_0_TOP_30K')\n",
    "acumulado_filename = os.path.join(ruta_top30K, 'top_10000_streaming_2021.csv')\n",
    "dtypes= {'Streams': str}\n",
    "\n",
    "df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1', dtype=dtypes)\n",
    "# df_acum = df_acum.drop(columns=['Semanas_creciendo_Artista'])\n",
    "\n",
    "for column in dtypes.keys():\n",
    "        if column in df_acum:\n",
    "            df_acum[column] = df_acum[column].str.replace('[^\\d]', '', regex=True).astype(int)\n",
    "\n",
    "df_acum['Streams'] = df_acum['Streams'].apply(lambda x: x.replace('.', '') if isinstance(x, str) and '.' in x else x).astype(int)\n",
    "print('Paso 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Año', 'Quarter', 'Semana', 'Fecha', 'Posición', 'Pos. Anterior',\n",
       "       'Pos. Máxima', 'Main Artist', 'Artista', 'Título', 'Sello', 'Label',\n",
       "       'Distribuidor', 'Streams', 'Streams Anterior', 'Streams Acum.',\n",
       "       'AdSupported', 'Premium', '% Dif.', 'Code', 'Release date', 'SPNL',\n",
       "       'Novedad', 'Spotify ISRC', 'ISRC', 'key', 'Release date str',\n",
       "       'Semanas_creciendo', 'Semanas_creciendo_Artista'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 2\n"
     ]
    }
   ],
   "source": [
    "# Ordena el DataFrame por 'Main Artist', 'Título' y 'Año' para asegurarte de que los registros estén en orden cronológico.\n",
    "df = df_acum.sort_values(by=['Main Artist', 'Título', 'Año', 'Semana'])\n",
    "\n",
    "# Inicializa la columna 'Evolutivo' con ceros.\n",
    "df['Semanas_creciendo'] = 0\n",
    "\n",
    "# Itera a través de las filas del DataFrame y calcula el evolutivo.\n",
    "current_artist = None\n",
    "current_title = None\n",
    "current_growth = 0\n",
    "print('Paso 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Main Artist'] == current_artist and row['Título'] == current_title:\n",
    "        # Si es la misma canción y el mismo artista que la semana anterior, verifica si el número de Streams aumentó.\n",
    "        if row['Streams'] > previous_streams:\n",
    "            current_growth += 1\n",
    "        else:\n",
    "            current_growth = 0\n",
    "    else:\n",
    "        # Si es una canción diferente o un artista diferente, reinicia el contador.\n",
    "        current_artist = row['Main Artist']\n",
    "        current_title = row['Título']\n",
    "        current_growth = 0\n",
    "    \n",
    "    # Actualiza la columna 'Evolutivo' en el DataFrame.\n",
    "    df.at[index, 'Semanas_creciendo'] = current_growth\n",
    "    \n",
    "    # Almacena los Streams actuales para la próxima comparación.\n",
    "    previous_streams = row['Streams']\n",
    "\n",
    "print('Paso 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 4\n"
     ]
    }
   ],
   "source": [
    "df['Semanas_creciendo'] = df['Semanas_creciendo'].astype(int)\n",
    "df = df.sort_values(by=['Año', 'Semana', 'Posición'], ascending=[True, True, True])\n",
    "print('Paso 4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Año', 'Quarter', 'Semana', 'Fecha', 'Posición', 'Pos. Anterior',\n",
       "       'Pos. Máxima', 'Main Artist', 'Artista', 'Título', 'Sello', 'Label',\n",
       "       'Distribuidor', 'Streams', 'Streams Anterior', 'Streams Acum.',\n",
       "       'AdSupported', 'Premium', '% Dif.', 'Code', 'Release date', 'SPNL',\n",
       "       'Novedad', 'Spotify ISRC', 'ISRC', 'key', 'Release date str',\n",
       "       'Semanas_creciendo', 'Semanas_creciendo_Artista'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 2\n",
      "Paso 3\n",
      "Paso 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### AHORA PARA ARTISTAS \n",
    "# Ordena el DataFrame por 'Main Artist', y 'Año' para asegurarte de que los registros estén en orden cronológico.\n",
    "df = df.drop(columns=['Semanas_creciendo_Artista'])\n",
    "\n",
    "df_artistas = df.groupby(['Main Artist', 'Año', 'Semana'])['Streams'].sum().reset_index()\n",
    "\n",
    "# Inicializa la columna 'Evolutivo' con ceros.\n",
    "df_artistas['Semanas_creciendo_Artista'] = 0\n",
    "\n",
    "# Itera a través de las filas del DataFrame y calcula el evolutivo.\n",
    "current_artist = None\n",
    "current_growth = 0\n",
    "print('Paso 2')\n",
    "for index, row in df_artistas.iterrows():\n",
    "    if row['Main Artist'] == current_artist:\n",
    "        # Si es la misma canción y el mismo artista que la semana anterior, verifica si el número de Streams aumentó.\n",
    "        if row['Streams'] > previous_streams:\n",
    "            current_growth += 1\n",
    "        else:\n",
    "            current_growth = 0\n",
    "    else:\n",
    "        # Si es una canción diferente o un artista diferente, reinicia el contador.\n",
    "        current_artist = row['Main Artist']\n",
    "        current_growth = 0\n",
    "    \n",
    "    # Actualiza la columna 'Evolutivo' en el DataFrame.\n",
    "    df_artistas.at[index, 'Semanas_creciendo_Artista'] = current_growth\n",
    "    \n",
    "    # Almacena los Streams actuales para la próxima comparación.\n",
    "    previous_streams = row['Streams']\n",
    "\n",
    "print('Paso 3')\n",
    "\n",
    "df = df.merge(df_artistas[['Main Artist', 'Año', 'Semana', 'Semanas_creciendo_Artista']], on=['Main Artist', 'Año', 'Semana'], how='left')\n",
    "df['Semanas_creciendo_Artista'] = df['Semanas_creciendo_Artista'].fillna(0)\n",
    "df['Semanas_creciendo_Artista'] = df['Semanas_creciendo_Artista'].astype(int)\n",
    "print('Paso 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Semanas_creciendo'] = df['Semanas_creciendo'].fillna(0)\n",
    "df['Semanas_creciendo'] = df['Semanas_creciendo'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 5\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(acumulado_filename, sep=\";\", index=False, encoding='latin-1', header=True)\n",
    "print('Paso 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambios nuria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cambios en los sellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2/ipykernel_14908/3375777645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Aplicar la función a la columna 'Sello'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquitar_anios\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sello'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sello'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquitar_anios\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Distribuidor'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Distribuidor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquitar_anios\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nuria01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\nuria01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nuria01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nuria01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2/ipykernel_14908/3375777645.py\u001b[0m in \u001b[0;36mquitar_anios\u001b[1;34m(texto)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mquitar_anios\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpatron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'^\\d+\\s+'\u001b[0m  \u001b[1;31m# Patrón para encontrar el año al principio del texto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatron\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Aplicar la función a la columna 'Sello'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nuria01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado 'df'\n",
    "\n",
    "# Definir una función para eliminar los dígitos que preceden a 'Records DK'\n",
    "def eliminar_digitos(texto):\n",
    "    patron = r'\\d+\\s*RECORDS DK'  # Patron para encontrar dígitos seguidos de 'Records DK'\n",
    "    return re.sub(patron, 'RECORDS DK', texto)\n",
    "\n",
    "# Definir una función para quitar los años de los valores de la columna 'Sello'\n",
    "def quitar_anios(texto):\n",
    "    patron = r'^\\d+\\s+'  # Patrón para encontrar el año al principio del texto\n",
    "    return re.sub(patron, '', texto)\n",
    "\n",
    "# Aplicar la función a la columna 'Sello'\n",
    "df['Label'] = df['Label'].apply(quitar_anios)\n",
    "df['Sello'] = df['Sello'].apply(quitar_anios)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(quitar_anios)\n",
    "\n",
    "# Aplicar la función a la columna 'Sello'\n",
    "df['Label'] = df['Label'].apply(eliminar_digitos)\n",
    "df['Sello'] = df['Sello'].apply(eliminar_digitos)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(eliminar_digitos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Eliminar todos los \"Label\" que tengan un formato similar: 1311288 RECORDS DK.\n",
    "df['Label'] = df['Label'].apply(lambda x: '-' if 'RECORDS DK' in x else x)\n",
    "df['Sello'] = df['Sello'].apply(lambda x: '-' if 'RECORDS DK' in x else x)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(lambda x: '-' if 'RECORDS DK' in x else x)\n",
    "\n",
    "# 2. y 3. Modificar sello y distribuidor según las condiciones dadas.\n",
    "df['Sello'] = df['Sello'].apply(lambda x: 'Distrokid' if 'PK INTERACTIVE / DISTROKID' in x else 'BOA MUSIC SPAIN' if 'ALTAFFONTE (BOA MUSIC SPAIN)' in x else x)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(lambda x: 'PK INTERACTIVE' if 'PK INTERACTIVE / DISTROKID' in x else 'ALTAFONTE' if 'ALTAFFONTE (BOA MUSIC SPAIN)' in x else x)\n",
    "\n",
    "# 4. Corregir ANGELS&#039; DAWN RECORDS.\n",
    "df['Distribuidor'] = df['Distribuidor'].str.replace(\"ANGELS&#039;\", \"ANGELS'\")\n",
    "\n",
    "# 5. Quitar el final de APARATAJE MUSIC GROUP,LLC.\n",
    "df['Label'] = df['Label'].str.replace(\" APARATAJE MUSIC GROUP,LLC\", \" APARATAJE MUSIC GROUP\")\n",
    "\n",
    "# 6. Reemplazar interrogantes con '-'.\n",
    "df.replace('???????-??????', '-', inplace=True)\n",
    "\n",
    "# 7. Reemplazar \"N.A.\" con '-'.\n",
    "df.replace('N.A.', '-', inplace=True)\n",
    "\n",
    "# 8. Unificar CANZION GROUP.\n",
    "df['Label'] = df['Label'].str.replace(\"CANZION GROUP LP\", \"CANZION GROUP\")\n",
    "\n",
    "# 9. Separar CDBABY como CD BABY.\n",
    "df['Label'] = df['Label'].str.replace(\"CDBABY\", \"CD BABY\")\n",
    "\n",
    "# 10. Cambiar CARINCO AG a CARINCO.\n",
    "df.replace('CARINCO AG', 'CARINCO', inplace=True)\n",
    "\n",
    "# 11. Cambiar DISTRO KID a DISTROKID.\n",
    "df['Label'] = df['Label'].str.replace(\"DISTRO KID\", \"DISTROKID\")\n",
    "\n",
    "# 12. Unificar diferentes formas de Entertainment One.\n",
    "df['Label'] = df['Label'].apply(lambda x: 'ENTERTAINMENT ONE' if 'ENTERTAINMENT ONE' in x else x)\n",
    "df['Sello'] = df['Sello'].apply(lambda x: 'ENTERTAINMENT ONE' if 'ENTERTAINMENT ONE' in x else x)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(lambda x: 'ENTERTAINMENT ONE' if 'ENTERTAINMENT ONE' in x else x)\n",
    "\n",
    "# 13. Corregir KEYVIEM MUSIC GROUP/EQUITY DISTRIBUTIO.\n",
    "df['Distribuidor'] = df['Distribuidor'].str.replace(\"KEYVIEM MUSIC GROUP / EQUITY DISTRIBUTIO\", \"KEYVIEM MUSIC GROUP/EQUITY DISTRIBUTION\")\n",
    "\n",
    "# 14. Reducir EMPIRE DISTRIBUTION a EMPIRE.\n",
    "df.replace('EMPIRE DISTRIBUTION', 'EMPIRE', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 15. Llenar valores de Sello con Label si está vacío o '-'.\n",
    "df['Sello'].fillna(df['Label'], inplace=True)\n",
    "df.loc[df['Sello'] == '-', 'Sello'] = df.loc[df['Sello'] == '-', 'Label']\n",
    "# 16. Llenar valores de Label con Sello si está vacío o '-'.\n",
    "df['Label'].fillna(df['Sello'], inplace=True)\n",
    "df.loc[df['Label'] == '-', 'Label'] = df.loc[df['Label'] == '-', 'Sello']\n",
    "\n",
    "# 17. Llenar valores de Label con Distribuidor si está vacío o '-'.\n",
    "df['Label'].fillna(df['Distribuidor'], inplace=True)\n",
    "df.loc[df['Label'] == '-', 'Label'] = df.loc[df['Label'] == '-', 'Distribuidor']\n",
    "\n",
    "# 18. Llenar valores de Distribuidor con Label si está vacío o '-'.\n",
    "df['Distribuidor'].fillna(df['Label'], inplace=True)\n",
    "df.loc[df['Distribuidor'] == '-', 'Distribuidor'] = df.loc[df['Distribuidor'] == '-', 'Label']\n",
    "\n",
    "# 19. Reemplazar valores en Distribuidor según las condiciones dadas.\n",
    "df.replace({'Distribuidor': {'INTERACTIVE': 'PK INTERACTIVE', 'IGROOVE AG': 'IGROOVE MUSIC', 'LA CUPULA': 'LA CUPULA MUSIC'}}, inplace=True)\n",
    "\n",
    "# 20. Reemplazar &amp; con &\n",
    "df.replace('&amp;', '&', regex=True, inplace=True)\n",
    "\n",
    "# 21. Cambiar KRAKEN DISTRIBUCION MUSICAL SL a KRAKEN DISTRIBUTION\n",
    "df.replace('KRAKEN DISTRIBUCION MUSICAL SL', 'KRAKEN DISTRIBUTION', inplace=True)\n",
    "\n",
    "# 22. Cambiar L 10 MUSIC a L10 MUSIC\n",
    "df['Label'] = df['Label'].str.replace('L 10 MUSIC', 'L10 MUSIC')\n",
    "df['Sello'] = df['Sello'].str.replace('L 10 MUSIC', 'L10 MUSIC')\n",
    "df['Distribuidor'] = df['Distribuidor'].str.replace('L 10 MUSIC', 'L10 MUSIC')\n",
    "\n",
    "# 23. Cambiar [PIAS] y algo más a PIAS DIGITAL\n",
    "df['Label'] = df['Label'].apply(lambda x: 'PIAS DIGITAL' if '[PIAS]' in x else x)\n",
    "df['Sello'] = df['Sello'].apply(lambda x: 'PIAS DIGITAL' if '[PIAS]' in x else x)\n",
    "df['Distribuidor'] = df['Distribuidor'].apply(lambda x: 'PIAS DIGITAL' if '[PIAS]' in x else x)\n",
    "\n",
    "# 24. Quitar \",\", \";\" o \".\" al final de los valores en Label, Sello y Distribuidor\n",
    "df['Label'] = df['Label'].str.rstrip(',;.')\n",
    "df['Sello'] = df['Sello'].str.rstrip(',;.')\n",
    "df['Distribuidor'] = df['Distribuidor'].str.rstrip(',;.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(acumulado_filename, sep=\";\", index=False, encoding='latin-1', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "hola\n",
      "hola\n",
      "(20490, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado 'df' con las columnas: Label, Sello, Distribuidor, Streams, y otras columnas si las hay.\n",
    "\n",
    "# Agrupar por las columnas especificadas y sumar los Streams\n",
    "df_agrupado = df.groupby(['Label', 'Sello', 'Distribuidor'])['Streams'].sum().reset_index()\n",
    "print('hola')\n",
    "# Ordenar el DataFrame de mayor a menor por Streams\n",
    "df_agrupado = df_agrupado.sort_values(by='Streams', ascending=False)\n",
    "print('hola')\n",
    "# Resetear el índice y eliminar la columna de índice anterior\n",
    "df_agrupado = df_agrupado.reset_index(drop=True).drop_duplicates()\n",
    "print('hola')\n",
    "print(df_agrupado.shape)\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "df_agrupado.to_excel('resultado_agrupado.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cambios sellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alco003\\AppData\\Local\\Temp\\1\\ipykernel_16232\\542470447.py:10: DtypeWarning: Columns (14,15,16,17,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1', dtype=dtypes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Año', 'Quarter', 'Semana', 'Fecha', 'Posición', 'Pos. Anterior',\n",
       "       'Pos. Máxima', 'Main Artist', 'Artista', 'Título', 'Sello', 'Label',\n",
       "       'Distribuidor', 'Streams', 'Streams Anterior', 'Streams Acum.',\n",
       "       'AdSupported', 'Premium', '% Dif.', 'Code', 'Release date', 'SPNL',\n",
       "       'Novedad', 'Spotify ISRC', 'ISRC', 'key', 'Release date str',\n",
       "       'Semanas_creciendo', 'Semanas_creciendo_Artista'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ruta_script = os.getcwd()\n",
    "ruta_top30K = os.path.join(os.path.dirname(ruta_script),'1_BBDD','6_0_TOP_30K')\n",
    "acumulado_filename = os.path.join(ruta_top30K, 'top_10000_streaming_2021.csv')\n",
    "ruta_sellos_nuevos = os.path.join(ruta_top30K, 'Limpieza_sellos.xlsx')\n",
    "dtypes= {'Streams': str}\n",
    "\n",
    "df_acum = pd.read_csv(acumulado_filename, sep=\";\", encoding='latin-1', dtype=dtypes)\n",
    "df_sellos = pd.read_excel(ruta_sellos_nuevos)\n",
    "for column in dtypes.keys():\n",
    "        if column in df_acum:\n",
    "            df_acum[column] = df_acum[column].str.replace('[^\\d]', '', regex=True).astype(int)\n",
    "\n",
    "df_acum['Streams'] = df_acum['Streams'].apply(lambda x: x.replace('.', '') if isinstance(x, str) and '.' in x else x).astype(int)\n",
    "\n",
    "df_acum['Fecha'] = pd.to_datetime(df_acum['Fecha'], format='%d/%m/%Y')\n",
    "\n",
    "filtered_df = df_acum[df_acum['Fecha'] >= '2023-04-01']\n",
    "\n",
    "# Hacer un merge de df_acum con df_sellos basado en Label y Sello_origen\n",
    "df_acum = pd.merge(df_acum, df_sellos, how='left', left_on='Label', right_on='Sello_origen')\n",
    "\n",
    "# Crear la nueva columna Sello_nuevo en df_acum\n",
    "df_acum['Sello_nuevo'] = df_acum['Sello_nuevo'].fillna(df_acum['Label'])\n",
    "\n",
    "# Eliminar las columnas innecesarias después del merge\n",
    "df_acum = df_acum.drop(columns=['Sello_origen'])\n",
    "\n",
    "# Eliminar los espacios y comas finales de la columna Sello_nuevo\n",
    "df_acum['Sello_nuevo'] = df_acum['Sello_nuevo'].str.rstrip(' ,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acum.to_csv(acumulado_filename, sep=\";\", index=False, encoding='latin-1', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f454e9305af220c09495407d97ffa04321718600c279a40070203c28da730f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
